# 实验报告三    大模型应用搭建



## 姓名：阮承沄           学号：2024211582        班级：2024211803

### 报告撰写时间：2025.5.26



## 一、实验目的

通过调用阿里云百炼的大模型平台API调用，实现在本机搭建可交互的大模型。从而掌握大模型搭建的基础步骤，了解大模型调用的底层原理。

## 二、实验环境

- 语言环境：Python3.12
- 编译器：PyCharm
- 大模型调用平台和使用的大模型：阿里云百炼，通义大模型

## 三、实验案例

### 0.申请API，创建.env文件管理环境

在阿里云百炼平台申请API后，在文件夹下新建.env文件，管理密钥环境变量

### 案例一：计算器智能体

#### （1）环境变量和依赖库导入

```python
import math
import os
from dotenv import find_dotenv, load_dotenv
from langchain.agents import initialize_agent, AgentType
from langchain_core.tools import Tool, BaseTool
load_dotenv(find_dotenv())
DASHSCOPE_API_KEY = os.environ["DASHSCOPE_API_KEY"]
from langchain_community.llms import Tongyi
```

- 使用 dotenv 管理 API 密钥，保证安全性
- 导入 LangChain 相关组件，包括代理初始化工具、工具基类和通义千问 LLM

#### （2）计算器工具的实现

```python
class SimpleCalculator(BaseTool):
    name: str = "calculator"
    description: str = "用于执行数学计算的工具，比如算术表达式、乘除加减等"

    def _run(self, query: str) -> str:
        try:
            allowed_names = {
                k: v for k, v in math.__dict__.items() if not k.startswith("__")
            }
            result = eval(query, {"__builtins__": {}}, allowed_names)
            print("结果: ", result)
            return str(result)
        except Exception as e:
            return f"计算出错: {e}"
```

1. **类定义与属性**：
   - 继承`BaseTool`：LangChain 中所有工具的基类。
   - `name`：工具的唯一标识符，用于代理调用。
   - `description`：工具功能描述，帮助 LLM 理解工具用途。
2. **核心方法 `_run`**：
   - **参数**：`query`（用户输入的数学表达式）。
   - **返回值**：计算结果的字符串形式。
3. **安全的`eval`实现**：
   - `{"__builtins__": {}}`：禁用 Python 内置函数（如`open`、`exec`），防止代码注入。
   - `allowed_names`：仅允许访问`math`模块中的公共函数 / 常量（过滤掉`__name__`等特殊属性）。

#### （3）大语言模型初始化

```python
llm = Tongyi(temperature=0.7)
```

- **Tongyi 模型**：接入阿里云的通义千问大语言模型。
- temperature 参数
  - 控制生成文本的随机性（0.0~1.0）。
  - **0.7**：平衡创造性与准确性，适合需要一定灵活性的任务。

#### （4）工具注册与代理初始化

```python
# 初始化计算器工具（内置 eval 工具）
calculator = SimpleCalculator()

# 将计算器注册为一个 Tool
tools = [
    Tool.from_function(
        func=calculator._run,
        name=calculator.name,
        description=calculator.description,
    )
]

# 初始化一个基于工具的 Agent
agent = initialize_agent(
    tools,
    llm,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True
)
```

1. **工具注册**
   - `Tool.from_function`：将自定义工具转换为 LangChain 的`Tool`对象。
   - 参数映射：
     - `func`：绑定工具的执行函数（即`SimpleCalculator._run`）。
     - `name`和`description`：传递给 LLM 的工具元信息。
2. **代理初始化**：
   - 核心参数：
     - `tools`：可用工具列表。
     - `llm`：语言模型。
     - `agent`：代理类型
       - `ZERO_SHOT_REACT_DESCRIPTION`：基于 ReAct 框架的零样本学习代理。
       - **ReAct 机制**：LLM 通过 "思考 - 行动 - 观察" 循环决定何时调用工具。
     - `verbose=True`：打印详细的推理过程（用于调试和理解）。

#### （5）交互

```python
# 示例：执行一个计算任务
question = "请帮我计算 (15.5 * 3) + (2023 / 7)"
result = agent.invoke({"input": question})
print("结果：", result)
```

#### 运行结果

![image-20250525213846160](C:\Users\ruanchengyun\AppData\Roaming\Typora\typora-user-images\image-20250525213846160.png)



### **自我探索——优化用户交互，实现用户输入和多轮对话**

实验手册给出的示例代码，是直接通过程序写死参数。为了实现用户输入和多轮对话，我将参考示例的代码替换成如下代码

```python
print("\n欢迎使用智能计算器助手！")
print("输入你的问题，输入 'exit' 结束对话。")

while True:
    question = input("\n请输入问题: ")
    result = agent.invoke({"input": question})
    print(result)
    if question.lower() == 'exit':
        print("感谢使用，再见！")
        break
```

1. **添加交互式循环**：
   - 使用`while True`创建一个无限循环，持续接收用户输入
   - 提供退出机制（输入 'exit' 结束对话）
2. **用户输入处理**：
   - 使用`input()`函数获取用户的问题
   - 将用户输入直接传递给代理进行处理
3. **结果展示优化**：
   - 更清晰地展示助手的回答
   - 保持 verbose 模式，便于查看代理的思考过程

#### 输出

```tex
欢迎使用智能计算器助手！
输入你的问题，输入 'exit' 结束对话。

请输入问题: 请帮我计算121+121


> Entering new AgentExecutor chain...
这是一个简单的加法计算问题，可以直接使用计算器工具进行计算。
Action: calculator
Action Input: 121+121结果:  242

Observation: 242
Thought:I now know the final answer
Final Answer: 242

> Finished chain.
{'input': '请帮我计算121+121', 'output': '242'}

请输入问题: 请帮我计算（222+156）*12-（12-32)/2


> Entering new AgentExecutor chain...
我需要进行数学计算来解决这个问题。
Action: calculator
Action Input: (222+156)*12-(12-32)/2结果:  4546.0

Observation: 4546.0
Thought:我现在知道最终答案。
Final Answer: 计算结果为4546。

> Finished chain.
{'input': '请帮我计算（222+156）*12-（12-32)/2', 'output': '计算结果为4546。'}

请输入问题: exit


> Entering new AgentExecutor chain...
I now know the final answer  
Final Answer: Goodbye! Have a great day!

> Finished chain.
{'input': 'exit', 'output': 'Goodbye! Have a great day!'}
感谢使用，再见！

进程已结束，退出代码为 0
```

<img src="C:\Users\ruanchengyun\AppData\Roaming\Typora\typora-user-images\image-20250525214720883.png" alt="image-20250525214720883" style="zoom: 33%;" />





### 案例二：⼩红书⽂案⽣成

```python
import os
from dotenv import find_dotenv, load_dotenv
load_dotenv(find_dotenv())
DASHSCOPE_API_KEY = os.environ["DASHSCOPE_API_KEY"]
from langchain_community.llms import Tongyi
from langchain.prompts import PromptTemplate

# 定义提示模板
xiaohongshu_template = """
你是一个专业的小红书文案写手，擅长用emoji和轻松活泼的语言风格撰写吸引人的文案。
请为以下产品/主题创作一篇小红书文案：
产品/主题：{product}
要求：
1. 文案包含标题和正文
2. 使用适当的emoji增加表现力
3. 包含至少3个主题标签(hashtag)
4. 语言风格轻松活泼，符合小红书平台调性
5. 可以适当使用网络流行语
"""

original_prompt = PromptTemplate(
    input_variables=["product"],
    template=xiaohongshu_template
)

llm = Tongyi(temperature=0.7)
xiaohongshu_chain = original_prompt | llm

optimization_template = """
根据以下反馈优化小红书文案：
原始文案：
{original_post}
用户反馈：
{feedback}
请保持原有风格和格式，根据反馈进行优化。
"""
optimization_prompt = PromptTemplate(
    input_variables=["original_post", "feedback"],
    template=optimization_template
)
optimization_chain = optimization_prompt | llm

def generate_readbook_post(product):
    print("生成初始文案...\n")
    initial_post = xiaohongshu_chain.invoke({'product': product})
    print(initial_post)

    while True:
        feedback = input("\n有任何修改建议吗？(直接回车接受当前文案，或输入修改建议)：")
        if not feedback.strip():
            break

        print("\n优化后的文案...\n")
        initial_post = optimization_chain.invoke({'original_post': initial_post, 'feedback': feedback})
        print(initial_post)

    return initial_post


# 使用示例
keyword = input("请输入产品/主题：")
if keyword:
    generate_readbook_post(keyword)


```

#### 输出结果



![image-20250525221408586](C:\Users\ruanchengyun\AppData\Roaming\Typora\typora-user-images\image-20250525221408586.png)

```tex
请输入产品/主题：北京邮电大学文创——卡套
生成初始文案...

**标题：北邮er的专属浪漫｜把“北邮”装进口袋吧！✨**

---

**正文：**  
宝子们！有没有想过，每天刷地铁卡、公交卡的时候，也能带着点校园情怀？🥰 北京邮电大学文创这次真的太会了！他们家出了一款超可爱的【北邮文创卡套】，直接把我拿捏住了～🫶

这款卡套设计感满满，简约又不失精致，上面还有北邮的经典元素，比如校徽、通信塔啥的，简直不要太戳心！❤️ 而且它不仅实用，还能成为你日常穿搭的小亮点哦～挂在包包上或者钥匙扣上，随时随地彰显你的北邮身份！💼🔑

重点来了！它的容量也很大，能放下好几张卡，学生卡、饭卡、交通卡统统搞定，妈妈再也不用担心我找不到卡啦！🤣✨

是不是已经心动了呢？快来pick这款既有颜值又有意义的卡套吧！让每一天都多一点小确幸～🌟

---

**#北邮文创 #校园周边 #大学生必备**

有任何修改建议吗？(直接回车接受当前文案，或输入修改建议)：多一些细节描述

优化后的文案...

**标题：北邮er的专属浪漫｜把“北邮”装进口袋吧！✨**

---

**正文：**  
宝子们！有没有想过，每天刷地铁卡、公交卡的时候，也能带着点校园情怀？🥰 北京邮电大学文创这次真的太会了！他们家出了一款超可爱的【北邮文创卡套】，直接把我拿捏住了～🫶

这款卡套设计感满满，简约又不失精致，细节处理得特别用心！它的正面印有北邮的经典元素，比如校徽和通信塔，线条流畅又充满科技感，简直不要太戳心！❤️ 而且材质选用的是优质PU皮，手感柔软细腻，耐磨又耐用，完全不用担心日常使用会刮花或者变形哦～

它不仅实用，还能成为你日常穿搭的小亮点哦～挂在包包上或者钥匙扣上，随时随地彰显你的北邮身份！💼🔑 卡套的背面还贴心地设计了一个小挂绳孔，方便随身携带，无论是通勤还是上课，都超级百搭！

重点来了！它的容量也很大，内部采用多层卡槽设计，能放下好几张卡，学生卡、饭卡、交通卡统统搞定，再也不用担心翻包找卡的尴尬啦！🤣✨ 每个卡槽都很贴合卡片，不会轻易滑落，安全感满分！

是不是已经心动了呢？快来pick这款既有颜值又有意义的卡套吧！让每一天都多一点小确幸～🌟

---

**#北邮文创 #校园周边 #大学生必备**

有任何修改建议吗？(直接回车接受当前文案，或输入修改建议)：



进程已结束，退出代码为 0
```





## 四、实验总结与反思

本次实验通过调用阿里云百炼的大模型 API，结合 LangChain 框架，分别完成了“计算器智能体”和“小红书文案生成”两个应用的搭建与优化，实现了从模型调用、工具封装、到用户交互的完整流程。实验不仅加深了我对大语言模型应用逻辑的理解，也提升了我将模型能力融合到实际业务场景的能力。

### 一、收获与亮点

1. **掌握 LangChain 工具链的使用流程**
   - 通过继承 `BaseTool` 自定义计算器工具，并使用 `Tool.from_function` 进行注册，实现了模型与工具的动态联动。
   - 熟悉了代理类型（如 `ZERO_SHOT_REACT_DESCRIPTION`）的行为机制，了解了 ReAct 框架中“思考-行动-观察”的推理流程。
2. **提升了模型提示词工程能力**
   - 在“小红书文案生成”中使用 `PromptTemplate` 精细设计了提示语，实现了风格统一、结构明确的文案输出。
   - 尝试引入用户反馈优化提示，完成了多轮优化链的构建，体现了“人类反馈+大模型”的协同潜力。
3. **增强了人机交互与实用性设计意识**
   - 优化了计算器智能体的用户输入逻辑，使用 `while` 循环实现了可持续交互与退出机制，显著提升了用户体验。
   - 在“小红书”案例中，增加了“是否修改”逻辑，引导用户参与生成过程，提高了文本个性化程度。

### 二、问题与反思

1. **工具链组合初期配置复杂，调试耗时较多**
    在初次配置 LangChain 与阿里云大模型时，API 密钥管理、依赖库安装及版本兼容性问题较为繁琐，调试成本偏高。在首次实验过程中，程序一直报错显示无法正确调用api。多次调试，寻找问题之后，发现首次配置的时候，将api密钥配置到了用户变量，于是后面的系统变量配置以及程序中通过.env文件配置全部失效。删除用户变量中的配置后，程序正常运行。

   后续建议在团队实践中编写统一的项目初始化脚本或配置指南。

   <img src="C:\Users\ruanchengyun\AppData\Roaming\Typora\typora-user-images\image-20250526143706961.png" alt="image-20250526143706961" style="zoom:50%;" />

2. **模型行为不确定性仍需控制与约束**
    如在“小红书”文案生成中，模型生成的长度与结构偶尔存在偏离预期的问题。提示词虽可一定程度缓解，但对提示词设计提出更高要求，后续可考虑增加输出格式约束或结构模板。























